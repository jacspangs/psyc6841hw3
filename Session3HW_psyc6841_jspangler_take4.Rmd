---
title: "R Notebook"
output: html_notebook
---

# Setup 

## Libraries & Conflicts

```{r, echo = FALSE, include= FALSE, warning = FALSE, message = FALSE}

suppressPackageStartupMessages({
library(readxl)
library(readr)
library(MASS)
library(dplyr)
library(tidyr)
library(broom)
library(ggplot2)
library(knitr)
library(RCurl)
library(DT)
library(modelr)
library(broom)
library(purrr)
library(pROC)
library(data.table)
library(VIM)
library(DT)
library(gridExtra)
library(caret)
library(Metrics)
library(randomForest)
library(e1071)
library(dtree)
library(corrplot)
library(DMwR2)
library(rsample)
library(skimr)
library(psych)
library(conflicted)
library(tree)
library(tidymodels)
library(janitor)
library(skimr)
library(GGally)
library(tidyquant)
library(doParallel) 
library(themis)
library(tidylog, warn.conflicts = FALSE)
})

conflict_prefer("distinct", "dplyr")
conflict_prefer("step_upsample", "recipes")
conflict_prefer("tune", "tune")
conflict_prefer("select", "dplyr")
conflict_prefer("select_if", "dplyr")
conflict_prefer("mutate_if", "dplyr")
conflict_prefer("mutate", "dplyr")
conflict_prefer("gather", "tidyr")
conflict_prefer("tune", "tune")
conflict_prefer("chisq.test", "stats")
conflict_prefer("filter", "dplyr")
conflict_prefer("skewness", "PerformanceAnalytics")
conflict_prefer("fit", "parsnip")
conflict_prefer("rmse", "yardstick")
conflict_prefer("map", "purrr")
conflict_prefer("vip", "vip")

for (f in getNamespaceExports("tidylog")) {
    conflicted::conflict_prefer(f, "tidylog", quiet = TRUE)
}
```

## Helper Functions 

```{r}
#From Matt Dancho DS4B 201

plot_ggpairs <- function(data, color = NULL, density_alpha = 0.5) {
   
    color_expr <- enquo(color)
   
    if (rlang::quo_is_null(color_expr)) {
       
        g <- data %>%
            ggpairs(lower = "blank")
       
    } else {
       
        color_name <- quo_name(color_expr)
       
        g <- data %>%
            ggpairs(mapping = aes_string(color = color_name),
                    lower = "blank", legend = 1,
                    diag = list(continuous = wrap("densityDiag",
                                                  alpha = density_alpha))) +
            theme(legend.position = "bottom")
    }
   
    return(g)
   
}

#From Matt Dancho DS4B 201
plot_hist_facet <- function(data, fct_reorder = FALSE, fct_rev = FALSE,
                            bins = 10, fill = palette_light()[[3]], color = "white", ncol = 5, scale = "free") {
   
    data_factored <- data %>%
        mutate_if(is.character, as.factor) %>%
        mutate_if(is.factor, as.numeric) %>%
        gather(key = key, value = value, factor_key = TRUE)
   
    if (fct_reorder) {
        data_factored <- data_factored %>%
            mutate(key = as.character(key) %>% as.factor())
    }
   
    if (fct_rev) {
        data_factored <- data_factored %>%
            mutate(key = fct_rev(key))
    }
   
    g <- data_factored %>%
        ggplot(aes(x = value, group = key)) +
        geom_histogram(bins = bins, fill = fill, color = color) +
        facet_wrap(~ key, ncol = ncol, scale = scale) +
        theme_tq()
   
    return(g)
   
}
```

# Load & Prep data

```{r}
Data <- read_excel("C:/Users/Jaclyn/Desktop/LearningR/AdvAnalytics/00_data/WA_Fn-UseC_-HR-Employee-Attrition.xlsx")
```

```{r}
#ADD ID
Data <- Data %>%
  mutate(ID = row_number()) %>%
  select(ID, EmployeeNumber, everything())
```

```{r}
#ATTRITION = FACTOR
Data <- Data %>%
  mutate(Attrition = as.factor(Attrition))
```

```{r}
#SPLIT DATA
set.seed(76)

data_split <- initial_split(Data, prop = 0.75, strata = "Attrition")

train_data <- training(data_split)

test_data <- testing(data_split)

tabyl(train_data$Attrition)

tabyl(test_data$Attrition)
```

```{r}
#10 FOLDS OF DATA FOR LATER
set.seed(76)
cv_folds <- vfold_cv(train_data, v = 10, strata = "Attrition")
```



## Ridge Regression


```{r}
ridge_spec <- logistic_reg(mixture = 0, penalty = tune()) %>%
  set_mode("classification") %>%
  set_engine("glmnet")
```


```{r}
set.seed(76)

recipe_obj <- recipe(formula = Attrition ~ ., data = train_data) %>%
  update_role(ID, EmployeeNumber, new_role = "ID") %>%
  step_mutate(JobLevel = factor(JobLevel)) %>% 
    step_mutate(StockOptionLevel = factor(StockOptionLevel)) %>% 
    step_YeoJohnson(YearsSinceLastPromotion, 
                    PerformanceRating,
                    YearsAtCompany,
                    MonthlyIncome,
                    TotalWorkingYears,
                    NumCompaniesWorked,
                    DistanceFromHome,
                    YearsInCurrentRole,
                    YearsWithCurrManager,
                    PercentSalaryHike) %>%
    step_center(all_numeric()) %>%
    step_scale(all_numeric()) %>%
    step_nzv(all_numeric()) %>% 
    step_zv(all_predictors()) %>% 
    themis::step_upsample(all_outcomes(), skip = TRUE) %>% 
    step_dummy(all_nominal(), -all_outcomes())

recipe_obj
```

```{r}
ridge_workflow <- workflow() %>% 
  add_recipe(recipe_obj) %>% 
  add_model(ridge_spec)
```



```{r}
penalty_grid <- grid_regular(penalty(range = c(-5, 5)), levels = 50)
penalty_grid
```


```{r}
tune_res <- tune_grid(
  ridge_workflow,
  resamples = cv_folds, 
  grid = penalty_grid
)
tune_res
```


```{r}
autoplot(tune_res)
```


```{r}
collect_metrics(tune_res)
```

The "best" values of this can be selected using `select_best()`, this function requires you to specify a `metric` that it should select against. 

```{r}
best_penalty <- select_best(tune_res, metric = "accuracy")
best_penalty

best_penalty_roc <- select_best(tune_res, metric = "roc_auc")
best_penalty_roc
```


```{r}
ridge_final <- finalize_workflow(ridge_workflow, best_penalty)
ridge_final_fit <- fit(ridge_final, data = train_data)
```

```{r}
ridge_final_fit
```
